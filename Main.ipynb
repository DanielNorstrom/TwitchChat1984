{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7436c41e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# TODO: add a field for trusted users. A user is trusted if they're a moderator or a long-time sub.\n",
    "# TODO: Discard bot messages. Consider also discarding mod messages since they're often the only ones allowed to send links.\n",
    "\n",
    "data = {} \n",
    "# of the form:\n",
    "# {\"channel1\":\n",
    "#    {\n",
    "#     \"messages\": [\"messsage1\", \"message2\"...],\n",
    "#     \"bad_messages\": [4, 18...], (indices of messages)\n",
    "#     \"viewers\": 482 (average)\n",
    "#    }\n",
    "#  \"channel2\":\n",
    "#   {...}\n",
    "# }\n",
    "\n",
    "\n",
    "# look through every data file\n",
    "for filename in os.listdir(\"InitialTestData\"):\n",
    "    if os.path.isfile(\"InitialTestData/\" + filename):\n",
    "        # get channel name\n",
    "        channel = filename.split(\"#\")[1].split(\".\")[0]\n",
    "        if not channel in data:\n",
    "            data[channel] = {\"viewers\": [], \"messages\": [], \"bad_messages\": []}\n",
    "        with open(\"InitialTestData/\" + filename) as file:\n",
    "            lines = []\n",
    "            for line in file.readlines():\n",
    "                # only care about timestamped lines. Others are overhead data that we don't mind.\n",
    "                if line[0] == \"[\":\n",
    "                    # get rid of the timestamp, we only want the message itself.\n",
    "                    line = line[line.find(\"] \")+2:]\n",
    "                    # check for standard message sent by a user.\n",
    "                    if line[0] == \"<\":\n",
    "                        lines.append(line)\n",
    "                    # check for overhead message stating viewer count.\n",
    "                    elif line[0:8] == \"VIEWERS:\":\n",
    "                        # for now add every viewer count to a list for averaging later on.\n",
    "                        data[channel][\"viewers\"].append(int(line[9:].replace(\"\\xa0\", \"\")))\n",
    "                    # check for overhead message stating a user was banned\n",
    "                    elif line[0:4] == \"BAN:\":\n",
    "                        # find most recent message sent by banned user and mark as bad message.\n",
    "                        for i, msg in reversed(list(enumerate(lines))):\n",
    "                            if line[5:].split(\" \")[0] + \">\" in msg:\n",
    "                                data[channel][\"bad_messages\"].append(len(data[channel][\"messages\"]) + i)\n",
    "                                break\n",
    "                    # check for overhead message stating a message was deleted.\n",
    "                    elif line[0:8] == \"DELETED:\":\n",
    "                        # find the deleted message and mark it as bad message.\n",
    "                        for i, msg in reversed(list(enumerate(lines))):\n",
    "                            if line[9:].split(\" (\")[0] + \"> \" + line[line.find(\" (\")+2:-1] in msg:\n",
    "                                data[channel][\"bad_messages\"].append(i)\n",
    "                                break\n",
    "            # remove names from messages and add to data.\n",
    "            for temp in lines:\n",
    "                temp = temp[temp.find(\">\")+2:]\n",
    "                # non-functioning attempt at anonomizing @-mentions.\n",
    "                #index = temp.find(\"@\")\n",
    "                #while index != -1:\n",
    "                #    temp.replace(temp[index:temp.find(\" \", index)], \"@user\")\n",
    "                #    index = temp.find(\"@\", index+1)\n",
    "                data[channel][\"messages\"].append(temp)\n",
    "# average viewer counts by channel.\n",
    "for channel in data.keys():\n",
    "    avg_viewers = int(sum(data[channel][\"viewers\"]) / len(data[channel][\"viewers\"]))\n",
    "    data[channel][\"viewers\"] = avg_viewers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c69ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: baalorlord average viewers: 1361 total messages: 5173 bad messages: 0\n",
      "channel: cirno_tv average viewers: 503 total messages: 8819 bad messages: 0\n",
      "channel: aicandii average viewers: 720 total messages: 10331 bad messages: 2\n",
      "channel: otzdarva average viewers: 6723 total messages: 11503 bad messages: 10\n",
      "channel: amouranth average viewers: 8123 total messages: 29611 bad messages: 790\n",
      "channel: fextralife average viewers: 13202 total messages: 10548 bad messages: 8\n",
      "channel: xqc average viewers: 51958 total messages: 364611 bad messages: 3818\n",
      "channel: cohhcarnage average viewers: 12895 total messages: 54824 bad messages: 45\n"
     ]
    }
   ],
   "source": [
    "for channel in data.keys():\n",
    "    print(\"channel:\", channel,\n",
    "          \"average viewers:\", data[channel][\"viewers\"],\n",
    "          \"total messages:\", len(data[channel][\"messages\"]),\n",
    "          \"bad messages:\", len(data[channel][\"bad_messages\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0548b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_channels = []\n",
    "for channel in data.keys():\n",
    "    if data[channel][\"viewers\"] >= 10000 or len(data[channel][\"bad_messages\"]) == 0:\n",
    "        discarded_channels.append(channel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851c9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "formatted_data = []\n",
    "for channel in data.keys():\n",
    "    if channel in discarded_channels:\n",
    "        continue\n",
    "    next_bad = 0\n",
    "    for index in range(len(data[channel][\"messages\"])):\n",
    "        row = []\n",
    "        if next_bad < len(data[channel][\"bad_messages\"]) and data[channel][\"bad_messages\"][next_bad] == index:\n",
    "            row = [\"bad\", data[channel][\"messages\"][index], channel]\n",
    "        else:\n",
    "            row = [\"good\", data[channel][\"messages\"][index], channel]\n",
    "        formatted_data.append(row)\n",
    "df = pd.DataFrame(formatted_data, columns=[\"status\", \"message\", \"channel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be44d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18fadc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39939</th>\n",
       "      <td>good</td>\n",
       "      <td>ammoNoxJAM ammoBearJAM ammoHey ammoNoxJAM ammo...</td>\n",
       "      <td>amouranth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43882</th>\n",
       "      <td>good</td>\n",
       "      <td>HypeApplause HypeApplause HypeApplause HypeApp...</td>\n",
       "      <td>amouranth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>good</td>\n",
       "      <td>NOT A HUNTSMAN\\n</td>\n",
       "      <td>aicandii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50993</th>\n",
       "      <td>good</td>\n",
       "      <td>pokemon &lt;3\\n</td>\n",
       "      <td>amouranth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23883</th>\n",
       "      <td>good</td>\n",
       "      <td>live for 25h holy shit\\n</td>\n",
       "      <td>amouranth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      status                                            message    channel\n",
       "39939   good  ammoNoxJAM ammoBearJAM ammoHey ammoNoxJAM ammo...  amouranth\n",
       "43882   good  HypeApplause HypeApplause HypeApplause HypeApp...  amouranth\n",
       "3520    good                                   NOT A HUNTSMAN\\n   aicandii\n",
       "50993   good                                       pokemon <3\\n  amouranth\n",
       "23883   good                           live for 25h holy shit\\n  amouranth"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6b764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer()), ('tfidf', TfidfTransformer()),('bayes', MultinomialNB())])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34baefb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 10289, 'bad': 0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       1.00      1.00      1.00     10289\n",
      "\n",
      "    accuracy                           1.00     10289\n",
      "   macro avg       1.00      1.00      1.00     10289\n",
      "weighted avg       1.00      1.00      1.00     10289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "temp = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        temp[guess] += 1\n",
    "print(temp)\n",
    "print(classification_report(test['status'], predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
